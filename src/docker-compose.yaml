version: '3.8'

networks:
  ml_monitoring:
    driver: bridge

services:
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    restart: always
    ports:
      - "2181:2181"
    healthcheck:
      test: [ "CMD", "nc", "-vz", "localhost", "2181" ]
      interval: 5s
      timeout: 5s
      retries: 10
    networks:
      - ml_monitoring

  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    restart: always
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:29092,OUTSIDE://127.0.0.1:9092
      KAFKA_LISTENERS: INSIDE://0.0.0.0:29092,OUTSIDE://0.0.0.0:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 72 # удаление сообщений через 72 часа
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_LOG_CLEANUP_POLICY: delete
    depends_on:
      zookeeper:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "nc", "-vz", "localhost", "9092" ]
      interval: 10s
      timeout: 5s
      retries: 10
    networks:
      - ml_monitoring

  kafdrop:
    image: obsidiandynamics/kafdrop
    container_name: kafdrop
    restart: always
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka:29092"
    depends_on:
      - kafka
    networks:
      - ml_monitoring

  pg_ml:
    container_name: pg_ml
    image: postgres:15
    restart: always
    environment:
      POSTGRES_DB: ml_db
      POSTGRES_USER: ml_user
      POSTGRES_PASSWORD: ml_password
    ports:
      - "5488:5432"
    volumes:
      - ./ml_monitoring_services/pg_ml:/var/lib/postgresql/data
    networks:
      - ml_monitoring

  grafana:
    container_name: grafana_1
    image: grafana/grafana:latest
    environment:
      TZ: "Europe/Moscow"
    restart: unless-stopped
    depends_on:
      - prometheus
    ports:
      - "3111:3000"
    volumes:
      - ./ml_monitoring_services/grafana:/var/lib/grafana
    networks:
      - ml_monitoring

  s3:
    container_name: s3
    image: minio/minio
    restart: always
    ports:
      - "9006:9000"
      - "9005:9001"
    volumes:
      - ./ml_monitoring_services/s3_storage:/data
    environment:
      MINIO_ACCESS_KEY: s3_access_key
      MINIO_SECRET_KEY: s3_secret_key
    command: server /data --console-address ":9001"
    networks:
      - ml_monitoring

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./ml_monitoring_services/prometheus:/etc/prometheus/
    container_name: prometheus
    hostname: prometheus
    command:
      - --config.file=/etc/prometheus/prometheus.yml
    ports:
      - 9090:9090
    restart: unless-stopped
    environment:
      TZ: "Europe/Moscow"
    depends_on:
      - cadvisor
    networks:
      - ml_monitoring

  node-exporter:
    image: prom/node-exporter:latest
    container_name: monitoring_node_exporter
    restart: unless-stopped
    expose:
      - 9100
    networks:
      - ml_monitoring

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.37.5
    container_name: cadvisor
    restart: always
    ports:
      - 8080:8080
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    depends_on:
      - redis
    networks:
      - ml_monitoring

  redis:
    image: redis:latest
    container_name: redis
    ports:
      - 6379:6379
    networks:
      - ml_monitoring

  images_uploader:
    build: images_uploader
    restart: always
    container_name: images_uploader
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - 8501:8501
    networks:
      - ml_monitoring

  person_inference:
    build: person_inference
    restart: always
    container_name: person_inference
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - ml_monitoring

  yolo_inference:
    build: yolo_inference
    restart: always
    container_name: yolo_inference
    depends_on:
      kafka:
        condition: service_healthy
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - ml_monitoring

volumes:
  pg_data_wh:
  pg_grafana:
  grafana:
  s3:
  prometheus:
  cadvisor:
